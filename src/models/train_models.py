"""
Script de entrenamiento para los modelos de clasificaciÃ³n de tumores y recomendaciÃ³n de tratamientos.
VersiÃ³n compatible con Python 3.13 sin TensorFlow.
"""

import numpy as np
import pandas as pd
import sys
import os
from pathlib import Path
import joblib
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
import warnings
warnings.filterwarnings('ignore')

# Agregar directorio padre al path
sys.path.append(str(Path(__file__).parent.parent))

try:
    from data.data_loader import DataLoader
except ImportError as e:
    print(f"Error importando DataLoader: {e}")
    sys.exit(1)

class SklearnImageClassifier:
    """Clasificador de imÃ¡genes usando caracterÃ­sticas extraÃ­das con scikit-learn."""
    
    def __init__(self, model_type='random_forest'):
        self.model_type = model_type
        self.model = None
        self.scaler = StandardScaler()
        self.label_encoder = LabelEncoder()
        self.is_trained = False
        
    def build_model(self):
        """Construir el modelo segÃºn el tipo especificado."""
        if self.model_type == 'random_forest':
            self.model = RandomForestClassifier(
                n_estimators=100,
                max_depth=10,
                random_state=42,
                n_jobs=-1
            )
        elif self.model_type == 'gradient_boosting':
            self.model = GradientBoostingClassifier(
                n_estimators=100,
                max_depth=6,
                random_state=42
            )
        else:
            self.model = LogisticRegression(
                random_state=42,
                max_iter=1000
            )
    
    def train(self, X_train, y_train, X_val=None, y_val=None):
        """Entrenar el modelo."""
        if self.model is None:
            self.build_model()
        
        # Codificar labels
        y_train_encoded = self.label_encoder.fit_transform(y_train)
        
        # Escalar caracterÃ­sticas
        X_train_scaled = self.scaler.fit_transform(X_train)
        
        print(f"ğŸ”„ Entrenando {self.model_type}...")
        self.model.fit(X_train_scaled, y_train_encoded)
        
        # EvaluaciÃ³n en entrenamiento
        train_score = self.model.score(X_train_scaled, y_train_encoded)
        print(f"ğŸ“Š PrecisiÃ³n en entrenamiento: {train_score:.4f}")
        
        # EvaluaciÃ³n en validaciÃ³n si estÃ¡ disponible
        if X_val is not None and y_val is not None:
            y_val_encoded = self.label_encoder.transform(y_val)
            X_val_scaled = self.scaler.transform(X_val)
            val_score = self.model.score(X_val_scaled, y_val_encoded)
            print(f"ğŸ“Š PrecisiÃ³n en validaciÃ³n: {val_score:.4f}")
        
        self.is_trained = True
        return {'train_accuracy': train_score}
    
    def predict_single_image(self, image_features):
        """Predecir clase de una sola imagen."""
        if not self.is_trained:
            raise ValueError("El modelo no ha sido entrenado")
        
        # Asegurar que sea un array 2D
        if len(image_features.shape) == 1:
            image_features = image_features.reshape(1, -1)
        
        # Escalar caracterÃ­sticas
        image_features_scaled = self.scaler.transform(image_features)
        
        # PredicciÃ³n
        prediction = self.model.predict(image_features_scaled)[0]
        probabilities = self.model.predict_proba(image_features_scaled)[0]
        
        # Decodificar label
        predicted_class = self.label_encoder.inverse_transform([prediction])[0]
        confidence = np.max(probabilities)
        
        return {
            'predicted_class': predicted_class,
            'confidence': confidence,
            'probabilities': {
                class_name: prob for class_name, prob in zip(
                    self.label_encoder.classes_, probabilities
                )
            }
        }
    
    def save_model(self, filepath):
        """Guardar el modelo entrenado."""
        model_data = {
            'model': self.model,
            'scaler': self.scaler,
            'label_encoder': self.label_encoder,
            'model_type': self.model_type,
            'is_trained': self.is_trained
        }
        joblib.dump(model_data, filepath)
        print(f"âœ… Modelo guardado en: {filepath}")

class SklearnTreatmentRecommender:
    """Recomendador de tratamientos usando modelos de scikit-learn."""
    
    def __init__(self, model_type='random_forest'):
        self.model_type = model_type
        self.model = None
        self.scaler = StandardScaler()
        self.label_encoder = LabelEncoder()
        self.is_trained = False
        
    def build_model(self):
        """Construir el modelo."""
        if self.model_type == 'random_forest':
            self.model = RandomForestClassifier(
                n_estimators=100,
                max_depth=8,
                random_state=42,
                n_jobs=-1
            )
        elif self.model_type == 'gradient_boosting':
            self.model = GradientBoostingClassifier(
                n_estimators=100,
                max_depth=6,
                random_state=42
            )
        else:
            self.model = LogisticRegression(
                random_state=42,
                max_iter=1000
            )
    
    def train(self, X_images, clinical_df, y_treatments):
        """Entrenar el recomendador."""
        if self.model is None:
            self.build_model()
        
        # Extraer caracterÃ­sticas de imÃ¡genes
        data_loader = DataLoader()
        image_features = data_loader.create_synthetic_image_features(len(clinical_df))
        
        # Preparar caracterÃ­sticas clÃ­nicas
        clinical_features, _ = data_loader.prepare_features_for_treatment(clinical_df)
        
        # Combinar caracterÃ­sticas
        combined_features = np.concatenate([image_features, clinical_features], axis=1)
        
        # Codificar tratamientos
        y_encoded = self.label_encoder.fit_transform(y_treatments)
        
        # Dividir datos
        X_train, X_val, y_train, y_val = train_test_split(
            combined_features, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
        )
        
        # Escalar caracterÃ­sticas
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_val_scaled = self.scaler.transform(X_val)
        
        print(f"ğŸ”„ Entrenando recomendador {self.model_type}...")
        self.model.fit(X_train_scaled, y_train)
        
        # EvaluaciÃ³n
        train_score = self.model.score(X_train_scaled, y_train)
        val_score = self.model.score(X_val_scaled, y_val)
        
        print(f"ğŸ“Š PrecisiÃ³n en entrenamiento: {train_score:.4f}")
        print(f"ğŸ“Š PrecisiÃ³n en validaciÃ³n: {val_score:.4f}")
        
        self.is_trained = True
        return {'train_accuracy': train_score, 'val_accuracy': val_score}
    
    def predict_single_case(self, image_features, clinical_data):
        """Predecir tratamiento para un caso."""
        if not self.is_trained:
            raise ValueError("El modelo no ha sido entrenado")
        
        # Crear un DataLoader para procesar correctamente las caracterÃ­sticas clÃ­nicas
        data_loader = DataLoader()
        
        # Crear un DataFrame temporal con los datos clÃ­nicos
        clinical_df_temp = pd.DataFrame([{
            'Age': clinical_data.get('Age', 50),
            'Sex': clinical_data.get('Sex', 'M'),
            'Clinical Note': clinical_data.get('Clinical Note', ''),
            'Treatment': 'surgery'  # Valor dummy para evitar error en prepare_features_for_treatment
        }])
        
        # Procesar los datos clÃ­nicos para obtener todas las caracterÃ­sticas
        clinical_df_temp = data_loader._clean_clinical_data(clinical_df_temp)
        clinical_features, _ = data_loader.prepare_features_for_treatment(clinical_df_temp)
        
        # Asegurar que las caracterÃ­sticas de imagen tengan la forma correcta
        if len(image_features.shape) == 1:
            image_features = image_features.reshape(1, -1)
        else:
            image_features = image_features.flatten().reshape(1, -1)
        
        # Tomar solo las primeras 19 caracterÃ­sticas de imagen
        image_features = image_features[:, :19]
        
        # Combinar caracterÃ­sticas
        combined_features = np.concatenate([image_features, clinical_features], axis=1)
        
        # Escalar y predecir
        combined_features_scaled = self.scaler.transform(combined_features)
        prediction = self.model.predict(combined_features_scaled)[0]
        probabilities = self.model.predict_proba(combined_features_scaled)[0]
        
        # Decodificar
        recommended_treatment = self.label_encoder.inverse_transform([prediction])[0]
        confidence = np.max(probabilities)
        
        return {
            'recommended_treatment': recommended_treatment,
            'confidence': confidence,
            'probabilities': {
                treatment: prob for treatment, prob in zip(
                    self.label_encoder.classes_, probabilities
                )
            }
        }
    
    def save_model(self, filepath):
        """Guardar el modelo."""
        model_data = {
            'model': self.model,
            'scaler': self.scaler,
            'label_encoder': self.label_encoder,
            'model_type': self.model_type,
            'is_trained': self.is_trained
        }
        joblib.dump(model_data, filepath + '.joblib')
        print(f"âœ… Recomendador guardado en: {filepath}.joblib")

def generate_synthetic_clinical_data(num_samples: int = 300) -> pd.DataFrame:
    """Generar datos clÃ­nicos sintÃ©ticos."""
    print("ğŸ”„ Generando datos clÃ­nicos sintÃ©ticos...")
    
    np.random.seed(42)
    
    data = []
    conditions = ['Brain_Glioma', 'Brain_Menin', 'Brain_Tumor']
    treatments = ['surgery', 'radiation therapy', 'chemotherapy', 'close monitoring']
    
    clinical_templates = [
        "Paciente presenta dolores de cabeza severos y nÃ¡useas frecuentes.",
        "Historia de convulsiones y alteraciones visuales progresivas.",
        "SÃ­ntomas neurolÃ³gicos con confusiÃ³n y pÃ©rdida de memoria.",
        "DÃ©ficit motor y alteraciones del habla evidentes.",
        "Cefaleas matutinas con vÃ³mitos proyectiles ocasionales.",
        "Deterioro cognitivo gradual con episodios de desorientaciÃ³n.",
        "Alteraciones del equilibrio y coordinaciÃ³n motora.",
        "Cambios de personalidad y comportamiento anÃ³malo.",
    ]
    
    for i in range(num_samples):
        age = np.random.randint(20, 80)
        sex = np.random.choice(['M', 'F'])
        condition = np.random.choice(conditions)
        clinical_note = np.random.choice(clinical_templates)
        treatment = np.random.choice(treatments)
        
        data.append({
            'Case ID': f'SYNTH_{i:03d}',
            'Condition': condition,
            'Age': age,
            'Sex': sex,
            'Clinical Note': clinical_note,
            'Treatment': treatment
        })
    
    return pd.DataFrame(data)

def train_image_classifier():
    """Entrenar el clasificador de imÃ¡genes usando caracterÃ­sticas extraÃ­das."""
    print("\nğŸ§  ENTRENANDO CLASIFICADOR DE IMÃGENES")
    print("=" * 50)
    
    # Cargar datos usando DataLoader
    data_loader = DataLoader(data_path="../../data/")
    
    # Intentar cargar datos clÃ­nicos reales
    try:
        clinical_df = data_loader.load_clinical_data()
        print(f"ğŸ“Š Datos clÃ­nicos cargados: {clinical_df.shape}")
        num_samples = len(clinical_df)
        
        # Usar labels reales
        y_images = data_loader.prepare_image_labels(clinical_df)
        class_names = data_loader.get_class_names('condition')
        
    except FileNotFoundError:
        print("âš ï¸ Archivo de datos clÃ­nicos no encontrado. Generando datos sintÃ©ticos...")
        clinical_df = generate_synthetic_clinical_data()
        num_samples = len(clinical_df)
        
        # Procesar datos sintÃ©ticos
        clinical_df = data_loader._clean_clinical_data(clinical_df)
        y_images = data_loader.prepare_image_labels(clinical_df)
        class_names = data_loader.get_class_names('condition')
    
    # Generar caracterÃ­sticas de imÃ¡genes sintÃ©ticas
    X_features = data_loader.create_synthetic_image_features(num_samples)
    
    print(f"ğŸ“Š CaracterÃ­sticas generadas: {X_features.shape}")
    print(f"ğŸ“‹ Clases: {class_names}")
    
    # Dividir datos
    X_train, X_test, y_train, y_test = train_test_split(
        X_features, y_images, test_size=0.2, random_state=42, stratify=y_images
    )
    
    print(f"ğŸ”„ Entrenamiento: {X_train.shape}, Prueba: {X_test.shape}")
    
    # Crear y entrenar modelo
    classifier = SklearnImageClassifier(model_type='random_forest')
    classifier.build_model()
    
    print("ğŸš€ Iniciando entrenamiento...")
    history = classifier.train(X_train, y_train, X_test, y_test)
    
    # EvaluaciÃ³n detallada
    print("\nğŸ“ˆ EvaluaciÃ³n detallada:")
    y_pred = classifier.model.predict(classifier.scaler.transform(X_test))
    y_test_encoded = classifier.label_encoder.transform(y_test)
    
    print(f"PrecisiÃ³n final: {accuracy_score(y_test_encoded, y_pred):.4f}")
    print("\nReporte de clasificaciÃ³n:")
    print(classification_report(y_test_encoded, y_pred, target_names=class_names))
    
    # Guardar modelo
    os.makedirs("../../models", exist_ok=True)
    classifier.save_model("../../models/sklearn_image_classifier.joblib")
    
    return classifier

def train_treatment_recommender():
    """Entrenar el recomendador de tratamientos."""
    print("\nğŸ’Š ENTRENANDO RECOMENDADOR DE TRATAMIENTOS")
    print("=" * 50)
    
    # Cargar datos clÃ­nicos
    data_loader = DataLoader(data_path="../../data/")
    
    try:
        clinical_df = data_loader.load_clinical_data()
        print(f"ğŸ“Š Datos clÃ­nicos cargados: {clinical_df.shape}")
    except FileNotFoundError:
        print("âš ï¸ Archivo de datos clÃ­nicos no encontrado. Generando datos sintÃ©ticos...")
        clinical_df = generate_synthetic_clinical_data()
        clinical_df = data_loader._clean_clinical_data(clinical_df)
    
    # Generar caracterÃ­sticas de imÃ¡genes sintÃ©ticas correspondientes
    num_samples = len(clinical_df)
    X_image_features = data_loader.create_synthetic_image_features(num_samples)
    
    # Preparar tratamientos
    y_treatments = clinical_df['Treatment'].values
    
    print(f"ğŸ”„ Datos preparados: {num_samples} muestras")
    print(f"ğŸ“‹ Tratamientos Ãºnicos: {np.unique(y_treatments)}")
    
    # Crear y entrenar modelo
    recommender = SklearnTreatmentRecommender(model_type='random_forest')
    recommender.build_model()
    
    print("ğŸš€ Iniciando entrenamiento del recomendador...")
    history = recommender.train(X_image_features, clinical_df, y_treatments)
    
    # Guardar modelo
    recommender.save_model("../../models/sklearn_treatment_recommender")
    
    return recommender

def test_models(image_classifier, treatment_recommender):
    """Probar los modelos entrenados."""
    print("\nğŸ§ª PROBANDO MODELOS ENTRENADOS")
    print("=" * 50)
    
    # Generar caracterÃ­sticas de imagen de prueba
    data_loader = DataLoader()
    test_image_features = data_loader.create_synthetic_image_features(1)[0]
    
    # Probar clasificador de imÃ¡genes
    print("ğŸ”¬ Probando clasificador de imÃ¡genes...")
    tumor_result = image_classifier.predict_single_image(test_image_features)
    print(f"Tumor detectado: {tumor_result['predicted_class']}")
    print(f"Confianza: {tumor_result['confidence']:.4f}")
    print(f"Probabilidades: {tumor_result['probabilities']}")
    
    # Probar recomendador de tratamientos
    print("\nğŸ’Š Probando recomendador de tratamientos...")
    clinical_data = {
        'Age': 45,
        'Sex': 'M',
        'Clinical Note': 'Paciente presenta dolores de cabeza severos y nÃ¡useas frecuentes.'
    }
    
    treatment_result = treatment_recommender.predict_single_case(test_image_features, clinical_data)
    print(f"Tratamiento recomendado: {treatment_result['recommended_treatment']}")
    print(f"Confianza: {treatment_result['confidence']:.4f}")
    print(f"Probabilidades: {treatment_result['probabilities']}")

def main():
    """FunciÃ³n principal para entrenar ambos modelos."""
    print("ğŸš€ INICIANDO ENTRENAMIENTO DE MODELOS DE MEDICINA PERSONALIZADA")
    print("ğŸ”¬ VersiÃ³n compatible con Python 3.13 (sin TensorFlow)")
    print("=" * 70)
    
    try:
        # Entrenar clasificador de imÃ¡genes
        print("ğŸ¯ Fase 1: Entrenamiento del clasificador de imÃ¡genes...")
        image_classifier = train_image_classifier()
        
        # Entrenar recomendador de tratamientos
        print("\nğŸ¯ Fase 2: Entrenamiento del recomendador de tratamientos...")
        treatment_recommender = train_treatment_recommender()
        
        # Probar modelos
        print("\nğŸ¯ Fase 3: Pruebas de los modelos...")
        test_models(image_classifier, treatment_recommender)
        
        print("\nâœ… ENTRENAMIENTO COMPLETADO EXITOSAMENTE")
        print("=" * 50)
        print("ğŸ“ Modelos guardados en: models/")
        print("ğŸŒ Los modelos estÃ¡n listos para usar en la API.")
        print("ğŸš€ Ejecuta: python ../../api_server.py para iniciar el servidor.")
        
        # Mostrar resumen final
        print("\nğŸ“Š RESUMEN DEL ENTRENAMIENTO:")
        print(f"âœ… Clasificador de imÃ¡genes: {image_classifier.model_type}")
        print(f"âœ… Recomendador de tratamientos: {treatment_recommender.model_type}")
        print(f"ğŸ¯ Sistema listo para medicina personalizada")
        
    except Exception as e:
        print(f"\nâŒ Error durante el entrenamiento: {e}")
        import traceback
        traceback.print_exc()
        print("\nğŸ’¡ Sugerencia: Verifica que todas las dependencias estÃ©n instaladas:")
        print("py -m pip install scikit-learn pandas numpy opencv-python joblib")

if __name__ == "__main__":
    main() 